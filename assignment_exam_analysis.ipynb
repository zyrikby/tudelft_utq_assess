{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://raw.githubusercontent.com/mbakker7/exploratory_computing_with_python/master/tudelft_logo.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Analyse exam results for UTQ ASSESS course\n",
    "This notebook was tested only on the machine with Ubuntu operating system and may not run on machines with other types of operating systems.\n",
    "\n",
    "This notebook:\n",
    "\n",
    "- *Developed by [Dr. Yury Zhauniarovich](https://zhauniarovich.com) (TPM - MAS - OG)* \n",
    "- *Inspired by the notebook developed by Dr. Ir. Hessel Winsemius (CEG - Water Management)*\n",
    "- *Contains information taken from the UTQ Assess Reader document*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants that control the behavior of the notebook\n",
    "\n",
    "IN_PATHS = {\n",
    "    'scores_data_file' : './data/test_data_with_grades.csv'\n",
    "}\n",
    "OUT_PATHS = {\n",
    "    'figs_dir' : './results/figs/',\n",
    "    'res_csv_dir' : './results/csvs/',\n",
    "}\n",
    "\n",
    "\n",
    "# Column StudentID\n",
    "INDEX_COLUMN = 'StudentID'\n",
    "# Column with grades. If there are no grades put None, then the grades will be computed automatically. \n",
    "GRADE_COLUMN = 'Grade' # None  \n",
    "\n",
    "# ID of the row with the information about the weights. It should be put into the INDEX_COLUMN\n",
    "ROWID_WEIGHT = 'weight'\n",
    "# ID of the row with the information about the minimum theoretical scores. It should be put into the INDEX_COLUMN\n",
    "ROWID_MIN_THEORETICAL_SCORE = 'min_score'\n",
    "# ID of the row with the information about the maximum theoretical scores. It should be put into the INDEX_COLUMN\n",
    "ROWID_MAX_THEORETICAL_SCORE = 'max_score'\n",
    "# ID of the row with the information about guess probablitiy. It should be put into the INDEX_COLUMN\n",
    "ROWID_GUESS_PROBA_PERC = 'guess_proba_perc'\n",
    "\n",
    "# If row with ROWID == ROWID_MIN_THEORETICAL_SCORE is not found then this value will be taken as the minimum theoretical score for all questions  \n",
    "DEFAULT_MIN_SCORE = 0\n",
    "# If row with ROWID == ROWID_MAX_THEORETICAL_SCORE is not found then this value will be taken as the maximum theoretical score for all questions  \n",
    "DEFAULT_MAX_SCORE = 10\n",
    "# If row with ROWID == ROWID_GUESS_PROBA_PERC is not found then this value will be taken as the default guess probability  \n",
    "DEFAULT_GUESS_PROBA_PERC = 0\n",
    "\n",
    "\n",
    "# Minimum possible grade\n",
    "MIN_GRADE = 1\n",
    "# Maximum possible grade\n",
    "MAX_GRADE = 10\n",
    "\n",
    "# CUTOFF SCORE - currently is not implemented in this notebook\n",
    "CUTOFF_SCORE = None\n",
    "# CUTOFF GRADE - minimum grade to pass the exam\n",
    "CUTOFF_GRADE = 5.8\n",
    "\n",
    "\n",
    "COMPUTED_GRADE_COLUMN = 'CALC_GRADE'\n",
    "STUDENT_SCORE_POINTS_COLUMN = 'STUDENT_SCORE_POINTS'\n",
    "\n",
    "# matplotlib constants\n",
    "FIGSIZE = (8, 6)      # the size of the final figures in inches\n",
    "SAVE_FIG = True       # should the figures be stored\n",
    "FIG_FMT = 'png'       # the format in which store the figures (matplotlib supported, e.g., png, pdf)\n",
    "TRANSPARENT_PNG=False # if the PNG figure should have a transparent background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "plt.style.use('seaborn-colorblind')\n",
    "\n",
    "# this package is requried to store styled dataframes as images\n",
    "# tested by storing them in the png format \n",
    "import dataframe_image as dfi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliary functions\n",
    "def read_data(pth):\n",
    "    data_df = pd.read_csv(pth, index_col=INDEX_COLUMN)\n",
    "\n",
    "    try:\n",
    "        grades = data_df[GRADE_COLUMN].copy()\n",
    "    except KeyError:\n",
    "        grades = None\n",
    "    else:\n",
    "        data_df = data_df.drop(columns=GRADE_COLUMN)\n",
    "        grades = grades.drop(\n",
    "            grades[grades.index.isin([\n",
    "                ROWID_WEIGHT,\n",
    "                ROWID_MIN_THEORETICAL_SCORE,\n",
    "                ROWID_MAX_THEORETICAL_SCORE,\n",
    "                ROWID_GUESS_PROBA_PERC,\n",
    "            ])].index\n",
    "        ).to_numpy(dtype=np.float64)\n",
    "    \n",
    "    number_of_criteria = len(data_df.columns)\n",
    "    weights_data = data_df[data_df.index==ROWID_WEIGHT]\n",
    "    if len(weights_data) > 0:\n",
    "        weights = weights_data.to_numpy(dtype=np.float64)[0]\n",
    "        data_df = data_df.drop(weights_data.index)\n",
    "    else:\n",
    "        weights = np.full(\n",
    "            shape=(number_of_criteria), \n",
    "            fill_value=1, \n",
    "            dtype=np.float64\n",
    "        )\n",
    "    min_theoretical_scores_data = data_df[data_df.index==ROWID_MIN_THEORETICAL_SCORE]\n",
    "    if len(min_theoretical_scores_data) > 0:\n",
    "        min_theoretical_scores = min_theoretical_scores_data.to_numpy(dtype=np.float64)[0]\n",
    "        data_df = data_df.drop(min_theoretical_scores_data.index)\n",
    "    else:\n",
    "        min_theoretical_scores = np.full(\n",
    "            shape=(number_of_criteria), \n",
    "            fill_value=DEFAULT_MIN_SCORE, \n",
    "            dtype=np.float64\n",
    "        )\n",
    "    \n",
    "    max_theoretical_scores_data = data_df[data_df.index==ROWID_MAX_THEORETICAL_SCORE]\n",
    "    if len(max_theoretical_scores_data) > 0:\n",
    "        max_theoretical_scores = max_theoretical_scores_data.to_numpy(dtype=np.float64)[0]\n",
    "        data_df = data_df.drop(max_theoretical_scores_data.index)\n",
    "    else:\n",
    "        max_theoretical_scores = np.full(\n",
    "            shape=(number_of_criteria), \n",
    "            fill_value=DEFAULT_MAX_SCORE, \n",
    "            dtype=np.float64\n",
    "        )\n",
    "    \n",
    "    guess_proba_data = data_df[data_df.index==ROWID_GUESS_PROBA_PERC]\n",
    "    if len(guess_proba_data) > 0:\n",
    "        guess_proba_perc = guess_proba_data.to_numpy(dtype=np.float64)[0]\n",
    "        data_df = data_df.drop(guess_proba_data.index)\n",
    "    else:\n",
    "        guess_proba_perc = np.full(\n",
    "            shape=(number_of_criteria), \n",
    "            fill_value=DEFAULT_GUESS_PROBA_PERC, \n",
    "            dtype=np.float64\n",
    "        )\n",
    "        # guess_proba_perc = np.array(\n",
    "\n",
    "        # )\n",
    "\n",
    "    return (\n",
    "        data_df, \n",
    "        grades, \n",
    "        weights, \n",
    "        min_theoretical_scores, \n",
    "        max_theoretical_scores, \n",
    "        guess_proba_perc,\n",
    "    )\n",
    "\n",
    "\n",
    "def save_fig(\n",
    "        fig, \n",
    "        fig_name: str, \n",
    "        fig_dir: str, \n",
    "        fig_fmt: str, \n",
    "        save: bool=True, \n",
    "        dpi: int=300,\n",
    "        transparent_png=True,\n",
    "    ):\n",
    "    \"\"\"This procedure stores the generated matplotlib figure to the specified \n",
    "    directory with the specified name and format.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fig : [type]\n",
    "        [description]\n",
    "    fig_name : str\n",
    "        [description]\n",
    "    fig_dir : str\n",
    "        [description]\n",
    "    fig_fmt : str\n",
    "        [description]\n",
    "    save : bool, optional\n",
    "        [description], by default True\n",
    "    dpi : int, optional\n",
    "        [description], by default 300\n",
    "    transparent_png : bool, optional\n",
    "        [description], by default True\n",
    "    \"\"\"\n",
    "    if not save:\n",
    "        return\n",
    "    fig_fmt = fig_fmt.lower()\n",
    "    fig_dir = os.path.join(fig_dir, fig_fmt)\n",
    "    if not os.path.exists(fig_dir):\n",
    "        os.makedirs(fig_dir)\n",
    "    pth = os.path.join(\n",
    "        fig_dir,\n",
    "        '{}.{}'.format(fig_name, fig_fmt.lower())\n",
    "    )\n",
    "    if fig_fmt == 'pdf':\n",
    "        fig.savefig(pth, bbox_inches='tight')\n",
    "    elif fig_fmt == 'png':\n",
    "        alpha = 0 if transparent_png else 1\n",
    "        axes = fig.get_axes()\n",
    "        fig.patch.set_alpha(alpha)\n",
    "        for ax in axes:\n",
    "            ax.patch.set_alpha(alpha)\n",
    "        fig.savefig(\n",
    "            pth, \n",
    "            bbox_inches='tight',\n",
    "            dpi=dpi,\n",
    "            # edgecolor='none',\n",
    "        )\n",
    "    else:\n",
    "        try:\n",
    "            fig.savefig(pth, bbox_inches='tight')\n",
    "        except Exception as e:\n",
    "            print(\"Cannot save figure: {}\".format(e)) \n",
    "\n",
    "\n",
    "def export_styled_df(\n",
    "    df_styler, \n",
    "    fig_name: str, \n",
    "    fig_dir: str, \n",
    "    fig_fmt: str, \n",
    "    save: bool=True,\n",
    "):\n",
    "    if not save:\n",
    "        return\n",
    "    fig_fmt = fig_fmt.lower()\n",
    "    fig_dir = os.path.join(fig_dir, fig_fmt)\n",
    "    if not os.path.exists(fig_dir):\n",
    "        os.makedirs(fig_dir)\n",
    "    pth = os.path.join(\n",
    "        fig_dir,\n",
    "        '{}.{}'.format(fig_name, fig_fmt.lower())\n",
    "    )\n",
    "    dfi.export(\n",
    "        df_styler,\n",
    "        pth,\n",
    "        max_cols=-1, # all columns\n",
    "    )\n",
    "\n",
    "\n",
    "def check_paths(in_paths, out_paths):\n",
    "    \"\"\"\n",
    "    This auxiliary function checks the input and output paths used for data \n",
    "    analysis.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_paths : Dict[srt, str]\n",
    "        A dictionary with input paths. If a key ends with '_dir' an \n",
    "        additional check is performed to figure out if the corresponding path \n",
    "        corresponds to an existing directory.  \n",
    "    out_paths : Dict[srt, str]\n",
    "        A dictionary with output paths. If a key ends with '_dir' the function \n",
    "        will trim the path to the directory. If the directory does not exist it \n",
    "        will be created.\n",
    "    \"\"\"    \n",
    "    for pth_key in in_paths:\n",
    "        pth = in_paths[pth_key]\n",
    "        if not os.path.exists(pth):\n",
    "            print('Path [{}] does not exist'.format(pth))\n",
    "        if pth_key.endswith('_dir') and (not os.path.isdir(pth)):\n",
    "            print('Path [{0}] does not correspond to a directory!'.format(pth))\n",
    "\n",
    "    for pth_key in out_paths:\n",
    "        pth = out_paths[pth_key]\n",
    "        if pth_key.endswith('_dir'):\n",
    "            abs_path = os.path.abspath(pth)\n",
    "        else:\n",
    "            abs_path = os.path.abspath(os.path.dirname(pth))\n",
    "        if not os.path.exists(abs_path):\n",
    "            print('Creating path: [{}]'.format(abs_path))\n",
    "            os.makedirs(abs_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it would be possible to save a matplotlib figure with the following command:\n",
    "# savefig(fig, 'figure_name')\n",
    "from functools import partial\n",
    "savefig = partial(save_fig, fig_dir=OUT_PATHS['figs_dir'], fig_fmt=FIG_FMT, save=SAVE_FIG, transparent_png=TRANSPARENT_PNG) \n",
    "export_df = partial(export_styled_df, fig_dir=OUT_PATHS['figs_dir'], fig_fmt=FIG_FMT, save=SAVE_FIG,)\n",
    "\n",
    "# checking the paths\n",
    "check_paths(IN_PATHS, OUT_PATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "scores_df, grades, weights, min_theoretical_scores, max_theoretical_scores, guess_proba_perc = read_data(IN_PATHS['scores_data_file'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criteria used: Speed, Fuel consumption, Design, Production costs, Aerodynamics, Summary, Correctness, Completeness, Presentation, Contribution\n"
     ]
    }
   ],
   "source": [
    "criteria = scores_df.columns\n",
    "print('Criteria used: {}'.format(', '.join(criteria)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of students: 31, number of questions: 10\n"
     ]
    }
   ],
   "source": [
    "# number of students and number of questions from the dataframe\n",
    "n_students, n_questions = scores_df.shape\n",
    "print(f'number of students: {n_students}, number of questions: {n_questions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "# normalized weights: I do not assume any preliminary knowledge about the sum of individual questions weighs\n",
    "normalized_weights = weights / sum(weights)\n",
    "print(normalized_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed</th>\n",
       "      <th>Fuel consumption</th>\n",
       "      <th>Design</th>\n",
       "      <th>Production costs</th>\n",
       "      <th>Aerodynamics</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudentID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Speed  Fuel consumption  Design  Production costs  Aerodynamics  \\\n",
       "StudentID                                                                    \n",
       "1              4                 4       6                 4             4   \n",
       "2             10                 5      10                 8             5   \n",
       "3              3                 5       6                 6             4   \n",
       "4             10                 5       7                 4             8   \n",
       "5              9                 5      10                 7             7   \n",
       "\n",
       "           Summary  Correctness  Completeness  Presentation  Contribution  \n",
       "StudentID                                                                  \n",
       "1                4            4             4             6             2  \n",
       "2               10            3             8             7             7  \n",
       "3                6            2             9             6             1  \n",
       "4               10            0             4             2             2  \n",
       "5                7           10             4             4             4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed</th>\n",
       "      <th>Fuel consumption</th>\n",
       "      <th>Design</th>\n",
       "      <th>Production costs</th>\n",
       "      <th>Aerodynamics</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudentID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Speed  Fuel consumption  Design  Production costs  Aerodynamics  \\\n",
       "StudentID                                                                    \n",
       "1            0.4               0.4     0.6               0.4           0.4   \n",
       "2            1.0               0.5     1.0               0.8           0.5   \n",
       "3            0.3               0.5     0.6               0.6           0.4   \n",
       "4            1.0               0.5     0.7               0.4           0.8   \n",
       "5            0.9               0.5     1.0               0.7           0.7   \n",
       "\n",
       "           Summary  Correctness  Completeness  Presentation  Contribution  \n",
       "StudentID                                                                  \n",
       "1              0.4          0.4           0.4           0.6           0.2  \n",
       "2              1.0          0.3           0.8           0.7           0.7  \n",
       "3              0.6          0.2           0.9           0.6           0.1  \n",
       "4              1.0          0.0           0.4           0.2           0.2  \n",
       "5              0.7          1.0           0.4           0.4           0.4  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_scores_df = pd.DataFrame((scores_df - min_theoretical_scores)/(max_theoretical_scores - min_theoretical_scores), dtype=np.float64)\n",
    "normalized_scores_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed</th>\n",
       "      <th>Fuel consumption</th>\n",
       "      <th>Design</th>\n",
       "      <th>Production costs</th>\n",
       "      <th>Aerodynamics</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudentID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Speed  Fuel consumption  Design  Production costs  Aerodynamics  \\\n",
       "StudentID                                                                    \n",
       "1           0.04              0.04    0.06              0.04          0.04   \n",
       "2           0.10              0.05    0.10              0.08          0.05   \n",
       "3           0.03              0.05    0.06              0.06          0.04   \n",
       "4           0.10              0.05    0.07              0.04          0.08   \n",
       "5           0.09              0.05    0.10              0.07          0.07   \n",
       "\n",
       "           Summary  Correctness  Completeness  Presentation  Contribution  \n",
       "StudentID                                                                  \n",
       "1             0.04         0.04          0.04          0.06          0.02  \n",
       "2             0.10         0.03          0.08          0.07          0.07  \n",
       "3             0.06         0.02          0.09          0.06          0.01  \n",
       "4             0.10         0.00          0.04          0.02          0.02  \n",
       "5             0.07         0.10          0.04          0.04          0.04  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_weighted_scores_df = pd.DataFrame(normalized_scores_df * normalized_weights, dtype=np.float64)\n",
    "normalized_weighted_scores_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed</th>\n",
       "      <th>Fuel consumption</th>\n",
       "      <th>Design</th>\n",
       "      <th>Production costs</th>\n",
       "      <th>Aerodynamics</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Contribution</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudentID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Speed  Fuel consumption  Design  Production costs  Aerodynamics  \\\n",
       "StudentID                                                                    \n",
       "1            4.0               4.0     6.0               4.0           4.0   \n",
       "2           10.0               5.0    10.0               8.0           5.0   \n",
       "3            3.0               5.0     6.0               6.0           4.0   \n",
       "4           10.0               5.0     7.0               4.0           8.0   \n",
       "5            9.0               5.0    10.0               7.0           7.0   \n",
       "\n",
       "           Summary  Correctness  Completeness  Presentation  Contribution  \n",
       "StudentID                                                                  \n",
       "1              4.0          4.0           4.0           6.0           2.0  \n",
       "2             10.0          3.0           8.0           7.0           7.0  \n",
       "3              6.0          2.0           9.0           6.0           1.0  \n",
       "4             10.0          0.0           4.0           2.0           2.0  \n",
       "5              7.0         10.0           4.0           4.0           4.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_points_df = pd.DataFrame(100*normalized_weighted_scores_df, dtype=np.float64)\n",
    "score_points_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(guess_proba_perc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# normalized weighted guess scores\n",
    "normalized_weighted_guess_scores = normalized_weights * guess_proba_perc / 100\n",
    "print(normalized_weighted_guess_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "guess_score_points = 100 * normalized_weighted_guess_scores\n",
    "print(guess_score_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Items Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p$ is the average, normalized score and has a value between 0 (no points) to 1 (full score). The higher $p$, the higher your students scored on this item, and the easier the question or the criterion. For closed questions, $p$ equals the fraction of students who answered the question correctly.\n",
    "\n",
    "$p$ is a reverse measure for the difficulty of an item.\n",
    "\n",
    "**Formulas:**\n",
    "\n",
    "$$\n",
    "p_j = \\frac{\\sum_{i=1}^{N_{stud}} s_i}{N_{stud}\\cdot S_j}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $p_j$ - the $p$-value for subquestion $j$,\n",
    "* $N_{stud}$ - the total number of students,\n",
    "* $S_j$ the maximum score of subquestion $j$, \n",
    "* $s_i$ the score of student $i$ on subquestion $j$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = scores_df.sum(axis=0) / (n_students * max_theoretical_scores)\n",
    "p_mean = p.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average difficulty: 0.66\n"
     ]
    }
   ],
   "source": [
    "print(f'Average difficulty: {p_mean:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item discrimination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Item discrimination** is the ability of an item to distinguish between good and poor performing students. If the item discrimination is high, good performing students answer the question correctly and poor performing students answer the question incorrectly.\n",
    "\n",
    "There are two item discrimination coefficients: $R_{it}$ and $R_{ir}$. You can always use RiR, but not always the $R_{it}$.\n",
    "\n",
    "Keep in mind that discrimination may be low if the item could be improved, but also if engaging in the learning activities did not contribute to getting a high score on this item. Either students already knew/mastered this before entering the course, or they did not get enough/effective learning activities during the course.\n",
    "\n",
    "|  $R_{it}$ and $R_{ir}$ | Item discrimination quality |\n",
    "|------------------------|-----------------------------|\n",
    "| **[0.4, 1]**           | Very good                   |\n",
    "| **[0.3, 0.4)**         | Good                        |\n",
    "| **[0.2, 0.3)**         | Mediocre, the question should be improved |\n",
    "| **[0.0, 0.2)**         | Bad, the question should not be |\n",
    "| **[-1.0, 0.0)**        | Bad, good students have answered the question incorrectly and vice versa |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Item Total Score ($R_{it}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formula:**\n",
    "\n",
    "$$\n",
    "R_{{it}_j} = \\frac{\\sum_{i=1}^{N_{stud}} (x_i - \\mu)(s_i - \\mu_j)}{\\sqrt{\\sum_{i=1}^{N_{stud}} (x_i - \\mu)^2 \\sum_{i=1}^{N_{stud} } (s_i - \\mu_j)^2}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $N_{stud}$ - the total number of students,\n",
    "* $x_i$ - the final score of student $i$,\n",
    "* $\\mu$ - the mean final score,\n",
    "* $s_i$ - the subquestion score of student $i$ on subquestion $j$,\n",
    "* $\\mu_j$ - the mean score on subquestion $j$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_norm_weighted_scores = normalized_weighted_scores_df.sum(axis=1)\n",
    "Rit = normalized_weighted_scores_df.corrwith(sum_norm_weighted_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Item Rest Score ($R_{ir}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Formula:**\n",
    "\n",
    "$$\n",
    "R_{{ir}_j} = \\frac{\\sum_{i=1}^{N_{stud}} ((x_i - s_i) - {\\~\\mu_J})(s_i - \\mu_j)}{\\sqrt{\\sum_{i=1}^{N_{stud}} ((x_i - s_i) - {\\~\\mu_J})^2 \\sum_{i=1}^{N_{stud} } (s_i - \\mu_j)^2}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $N_{stud}$ - the total number of students,\n",
    "* $x_i$ - the final score of student $i$,\n",
    "* $\\mu$ - the mean final score,\n",
    "* $s_i$ - the subquestion score of student $i$ on subquestion $j$,\n",
    "* $\\mu_j$ - the mean score on subquestion $j$,\n",
    "* ${\\~\\mu_J}$ - the mean test score calculated from all\n",
    "subquestion scores minus the score from subquestion $j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumrest_norm_weighted_scores = pd.DataFrame([normalized_weighted_scores_df.drop(columns=i).sum(axis=1) for i in normalized_weighted_scores_df.columns], index=normalized_weighted_scores_df.columns).transpose()\n",
    "Rir = normalized_weighted_scores_df.corrwith(sumrest_norm_weighted_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Reliability of the test (Cronbach’s alpha)\n",
    "\n",
    "Reliability coefficients are a measure of whether students are performing consistently well on all test items. This is also called the *internal consistency of the test*. It is the extent to which the outcome of the assessment is **not** influenced by coincidence.\n",
    "\n",
    "***Cronbach’s alpha ($\\alpha$)*** estimates the test-retest by considering each question in the test as a separate test and then calculating the correlation between the questions.\n",
    "\n",
    "The **value of $\\alpha$** always lies between 1 and 0. The closer the value is to 1, the smaller the measurement error. A lower reliability can mean that a student whose ‘true score’ is just above the cut-off score may fail the test due to test inaccuracy. Test reliability is very important when the consequences of the test results are large, and therefore the reliability coefficient should be higher for tests of higher stakes. Grades can be considered reliable if Cronbach’s alpha is high enough.\n",
    "\n",
    "\n",
    "| Type of assessment                                           | Cronbach’s alpha |\n",
    "|--------------------------------------------------------------|------------------|\n",
    "| High stake assessment (e.g.,  the only assessment of course) | $\\alpha \\ge 0.8$            |\n",
    "| Medium/low stake assessment  (e.g., 50% of final grade):     | $\\alpha \\ge 0.7$          |\n",
    "| Formative assessment (e.g., 0% of final grade)               | $\\alpha \\ge 0.6$          |\n",
    "\n",
    "\n",
    "**Formulas:**\n",
    "\n",
    "$$\n",
    "\\alpha = \\frac{K}{K-1}\\cdot \\frac{\\sigma_x^2 - \\sum_{j=1}^K \\sigma_j^2}{\\sigma_x^2}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $\\alpha$ - the reliability coefficient,\n",
    "* $K$ - the total number of subquestions,\n",
    "* $\\sigma_x^2$ - the variance in the final scores of all students\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "\\sigma_x^2 = \\frac{1}{N_{stud}}\\cdot \\sum_{i=1}^{N_{stud}} (x_i - \\mu)^2\n",
    "$$\n",
    "\n",
    "* $N_{stud}$ - the total number of students, \n",
    "* $x_i$ - the final score of student $i$,\n",
    "* $\\mu$ - the mean final score.\n",
    "\n",
    "$$\n",
    "\\sigma_j^2 = \\frac{1}{N_{stud}}\\cdot \\sum_{i=1}^{N_{stud}} (s_i - \\mu_j)^2\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $s_i$ - the subquestion score of student $i$ on subquestion $j$,\n",
    "* $\\mu_j$ - the mean score on subquestion j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_norm_weighted_scores = normalized_weighted_scores_df.sum(axis=1)\n",
    "stdev = normalized_weighted_scores_df.std(axis=0)\n",
    "sigx = sum_norm_weighted_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_sp_per_student = score_points_df.sum(axis=1)\n",
    "stdev_sp = score_points_df.std(axis=0)\n",
    "sigx_sp = sum_sp_per_student.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = n_questions/(n_questions - 1)*(sigx**2-(stdev**2).sum())/sigx**2\n",
    "# alpha_perc = n_questions/(n_questions - 1)*(sigx_perc**2-(stdev_perc**2).sum())/sigx_perc**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cronbach's alpha: 0.77\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cronbach's alpha: {alpha:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Error of Measurement ($SEM$)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test theory assumes that every student has a true score, which reflects that student's actual capability in the area of expertise that an assessment is testing. If a student would take the same test an infinite amount of times, the average of all these scores would constitute the true score. However, *the score of a student taking a test once is always the measurement of the true score plus the measurement error, either systematic of accidental*.\n",
    "\n",
    "For the sake of reliability of an assessment, which primary goal is to sort students in terms of pass and fail, it is important that this error of measurement is as small as possible, so that based on actual capability, a student passing should actually pass and a student failing should actually fail.\n",
    "\n",
    "**Standard Error of Measurement ($SEM$)** is used to find the confidence interval for individual students with which can be ascertained that the pass or fail they have achieved reflects actual capability.\n",
    "\n",
    "**Formula:**\n",
    "\n",
    "$$\n",
    "SEM(x) = SD(x)\\sqrt{1 - \\alpha}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEM = sigx*(1-alpha)**0.5\n",
    "SEM_SP = sigx_sp*(1-alpha)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Error of Measurement (for normalized weighted scores): 0.0620\n",
      "Standard Error of Measurement (in score points): 6.20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Standard Error of Measurement (for normalized weighted scores): {SEM:.4f}\")\n",
    "print(f\"Standard Error of Measurement (in score points): {SEM_SP:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confidence Interval of Scores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having $SEM$, we can  calculate the 68% and 95% confidence intervals. \n",
    "- 68%: $[test\\_score-1*SEM, test\\_score+1*SEM]$\n",
    "- 95%: $[test\\_score-2*SEM, test\\_score+2*SEM]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_points_df[STUDENT_SCORE_POINTS_COLUMN] = score_points_df[criteria].sum(axis=1)\n",
    "score_points_df['MIN_CI_68'] = score_points_df[STUDENT_SCORE_POINTS_COLUMN] - 1*SEM_SP\n",
    "score_points_df['MAX_CI_68'] = score_points_df[STUDENT_SCORE_POINTS_COLUMN] + 1*SEM_SP\n",
    "score_points_df['MIN_CI_95'] = score_points_df[STUDENT_SCORE_POINTS_COLUMN] - 2*SEM_SP\n",
    "score_points_df['MAX_CI_95'] = score_points_df[STUDENT_SCORE_POINTS_COLUMN] + 2*SEM_SP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed</th>\n",
       "      <th>Fuel consumption</th>\n",
       "      <th>Design</th>\n",
       "      <th>Production costs</th>\n",
       "      <th>Aerodynamics</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>STUDENT_SCORE_POINTS</th>\n",
       "      <th>MIN_CI_68</th>\n",
       "      <th>MAX_CI_68</th>\n",
       "      <th>MIN_CI_95</th>\n",
       "      <th>MAX_CI_95</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudentID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>35.798563</td>\n",
       "      <td>48.201437</td>\n",
       "      <td>29.597125</td>\n",
       "      <td>54.402875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.798563</td>\n",
       "      <td>79.201437</td>\n",
       "      <td>60.597125</td>\n",
       "      <td>85.402875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>41.798563</td>\n",
       "      <td>54.201437</td>\n",
       "      <td>35.597125</td>\n",
       "      <td>60.402875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>45.798563</td>\n",
       "      <td>58.201437</td>\n",
       "      <td>39.597125</td>\n",
       "      <td>64.402875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>60.798563</td>\n",
       "      <td>73.201437</td>\n",
       "      <td>54.597125</td>\n",
       "      <td>79.402875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Speed  Fuel consumption  Design  Production costs  Aerodynamics  \\\n",
       "StudentID                                                                    \n",
       "1            4.0               4.0     6.0               4.0           4.0   \n",
       "2           10.0               5.0    10.0               8.0           5.0   \n",
       "3            3.0               5.0     6.0               6.0           4.0   \n",
       "4           10.0               5.0     7.0               4.0           8.0   \n",
       "5            9.0               5.0    10.0               7.0           7.0   \n",
       "\n",
       "           Summary  Correctness  Completeness  Presentation  Contribution  \\\n",
       "StudentID                                                                   \n",
       "1              4.0          4.0           4.0           6.0           2.0   \n",
       "2             10.0          3.0           8.0           7.0           7.0   \n",
       "3              6.0          2.0           9.0           6.0           1.0   \n",
       "4             10.0          0.0           4.0           2.0           2.0   \n",
       "5              7.0         10.0           4.0           4.0           4.0   \n",
       "\n",
       "           STUDENT_SCORE_POINTS  MIN_CI_68  MAX_CI_68  MIN_CI_95  MAX_CI_95  \n",
       "StudentID                                                                    \n",
       "1                          42.0  35.798563  48.201437  29.597125  54.402875  \n",
       "2                          73.0  66.798563  79.201437  60.597125  85.402875  \n",
       "3                          48.0  41.798563  54.201437  35.597125  60.402875  \n",
       "4                          52.0  45.798563  58.201437  39.597125  64.402875  \n",
       "5                          67.0  60.798563  73.201437  54.597125  79.402875  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_points_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways how to calculate grades: \n",
    "* when the cut-off score is calculated automatically,\n",
    "* when you specify cut-off score\n",
    "\n",
    "**Formulas (the grades are between 1 and 10 in this case):**\n",
    "\n",
    "- When the cut-off score is calculated automatically\n",
    "\n",
    "$$\n",
    "grade = max\\{1; 1+9 * \\frac{(s - gs)}{(ms - gs)}\\}\n",
    "$$\n",
    "\n",
    "$$\n",
    "grade = max\\{1; 10 * \\frac{(s - gs)}{(ms - gs)}\\}\n",
    "$$\n",
    "\n",
    "- When you specify cut-off score\n",
    "\n",
    "$$\n",
    "grade = \\begin{cases} 1 + s*\\frac{5}{cos}, & s < cos, \\\\  \\frac{6ms - 10cos + 4s}{ms - cos},  & s \\ge cos\\end{cases}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "* $grade$ - the resulting grade\n",
    "* $s$ - the obtained score by an individual student\n",
    "* $gs$ - the guessing score (average obtained score of random guessing\n",
    "* $ms$ - the maximum score \n",
    "* $max\\{a;b\\}$ the maximum value of $a$ and $b$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_sum(score_sp, guess_sp, max_sp=100):\n",
    "    grade = max(MIN_GRADE, MIN_GRADE + (MAX_GRADE - MIN_GRADE)*(score_sp - guess_sp) / (max_sp - guess_sp))\n",
    "    return grade if grade < MAX_GRADE else MAX_GRADE \n",
    "\n",
    "def grade_mult(score_sp, guess_sp, max_sp=100):\n",
    "    grade = max(MIN_GRADE, MIN_GRADE + (MAX_GRADE - MIN_GRADE)*(score_sp - guess_sp) / (max_sp - guess_sp))\n",
    "    return grade if grade < MAX_GRADE else MAX_GRADE\n",
    "\n",
    "# TODO: Implement the score\n",
    "# def grade_with_cutoff(cutoff_score_sp, score_sp, guess_sp, max_sp=100, cutoff_grade = ):\n",
    "#     if score_sp < cutoff_sp:\n",
    "#         grade = 1 + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if in the initial dataset there were grades then we add this to the final students dataset too\n",
    "if grades is not None:\n",
    "    score_points_df[GRADE_COLUMN] = grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_sp_sum = guess_score_points.sum()\n",
    "if CUTOFF_SCORE:\n",
    "    # TODO: to implement\n",
    "    pass\n",
    "else: \n",
    "    score_points_df[COMPUTED_GRADE_COLUMN] = score_points_df.apply(\n",
    "        lambda row: grade_sum(row[STUDENT_SCORE_POINTS_COLUMN], guess_sp_sum),\n",
    "        axis = 1 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speed</th>\n",
       "      <th>Fuel consumption</th>\n",
       "      <th>Design</th>\n",
       "      <th>Production costs</th>\n",
       "      <th>Aerodynamics</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Correctness</th>\n",
       "      <th>Completeness</th>\n",
       "      <th>Presentation</th>\n",
       "      <th>Contribution</th>\n",
       "      <th>STUDENT_SCORE_POINTS</th>\n",
       "      <th>MIN_CI_68</th>\n",
       "      <th>MAX_CI_68</th>\n",
       "      <th>MIN_CI_95</th>\n",
       "      <th>MAX_CI_95</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CALC_GRADE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>StudentID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>35.798563</td>\n",
       "      <td>48.201437</td>\n",
       "      <td>29.597125</td>\n",
       "      <td>54.402875</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>66.798563</td>\n",
       "      <td>79.201437</td>\n",
       "      <td>60.597125</td>\n",
       "      <td>85.402875</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>41.798563</td>\n",
       "      <td>54.201437</td>\n",
       "      <td>35.597125</td>\n",
       "      <td>60.402875</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>45.798563</td>\n",
       "      <td>58.201437</td>\n",
       "      <td>39.597125</td>\n",
       "      <td>64.402875</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>60.798563</td>\n",
       "      <td>73.201437</td>\n",
       "      <td>54.597125</td>\n",
       "      <td>79.402875</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Speed  Fuel consumption  Design  Production costs  Aerodynamics  \\\n",
       "StudentID                                                                    \n",
       "1            4.0               4.0     6.0               4.0           4.0   \n",
       "2           10.0               5.0    10.0               8.0           5.0   \n",
       "3            3.0               5.0     6.0               6.0           4.0   \n",
       "4           10.0               5.0     7.0               4.0           8.0   \n",
       "5            9.0               5.0    10.0               7.0           7.0   \n",
       "\n",
       "           Summary  Correctness  Completeness  Presentation  Contribution  \\\n",
       "StudentID                                                                   \n",
       "1              4.0          4.0           4.0           6.0           2.0   \n",
       "2             10.0          3.0           8.0           7.0           7.0   \n",
       "3              6.0          2.0           9.0           6.0           1.0   \n",
       "4             10.0          0.0           4.0           2.0           2.0   \n",
       "5              7.0         10.0           4.0           4.0           4.0   \n",
       "\n",
       "           STUDENT_SCORE_POINTS  MIN_CI_68  MAX_CI_68  MIN_CI_95  MAX_CI_95  \\\n",
       "StudentID                                                                     \n",
       "1                          42.0  35.798563  48.201437  29.597125  54.402875   \n",
       "2                          73.0  66.798563  79.201437  60.597125  85.402875   \n",
       "3                          48.0  41.798563  54.201437  35.597125  60.402875   \n",
       "4                          52.0  45.798563  58.201437  39.597125  64.402875   \n",
       "5                          67.0  60.798563  73.201437  54.597125  79.402875   \n",
       "\n",
       "           Grade  CALC_GRADE  \n",
       "StudentID                     \n",
       "1            7.1        4.78  \n",
       "2            6.9        7.57  \n",
       "3            4.2        5.32  \n",
       "4            5.7        5.68  \n",
       "5            7.7        7.03  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_points_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Related to Whole Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_res_data = {\n",
    "    'min_student_score_points' : score_points_df[STUDENT_SCORE_POINTS_COLUMN].min(),\n",
    "    'max_student_score_points' : score_points_df[STUDENT_SCORE_POINTS_COLUMN].max(),\n",
    "    'min_computed_grade' : score_points_df[COMPUTED_GRADE_COLUMN].min(),\n",
    "    'max_computed_grade' : score_points_df[COMPUTED_GRADE_COLUMN].max(),\n",
    "    'p_mean' : p_mean,\n",
    "    'Rit_mean' : Rit.mean(),\n",
    "    'Rir_mean' : Rir.mean(),\n",
    "    'alpha' : alpha,\n",
    "    'SEM_SP' : SEM_SP,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df = pd.DataFrame.from_dict(final_test_res_data, orient='index', columns=['Value'])\n",
    "final_test_df.index.rename('Parameter', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_df.to_csv(\n",
    "    os.path.join(OUT_PATHS['res_csv_dir'], 'final_test_data.csv'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Related to Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_res_data = {\n",
    "    'weights' : weights,\n",
    "    'min_theoretical_scores' : min_theoretical_scores,\n",
    "    'max_theoretical_scores' : max_theoretical_scores,\n",
    "    'guess_proba_perc' : guess_proba_perc,\n",
    "    'normalized_weights' : normalized_weights, \n",
    "    'min_scores' : scores_df[criteria].min(axis=0),\n",
    "    'max_scores' : scores_df[criteria].max(axis=0),\n",
    "    'min_normalized_scores' : normalized_scores_df[criteria].min(axis=0),\n",
    "    'max_normalized_scores' : normalized_scores_df[criteria].max(axis=0),\n",
    "    'min_normalized_weighted_scores' : normalized_weighted_scores_df[criteria].min(axis=0),\n",
    "    'max_normalized_weighted_scores' : normalized_weighted_scores_df[criteria].max(axis=0),\n",
    "    'min_student_score_points' : score_points_df[criteria].min(axis=0),\n",
    "    'max_student_score_points' : score_points_df[criteria].max(axis=0),\n",
    "    'avg_student_score_points' : score_points_df[criteria].mean(axis=0),\n",
    "    'guess_score_points' : guess_score_points,\n",
    "    'p' : p,\n",
    "    'Rit' : Rit,\n",
    "    'Rir' : Rir,\n",
    "    'stdev' : stdev,\n",
    "    'stdev_sp' : stdev_sp,\n",
    "}\n",
    "\n",
    "questions_res_df = pd.DataFrame.from_records(\n",
    "    questions_res_data,\n",
    "    index = criteria,\n",
    "    columns = questions_res_data.keys(),\n",
    ")\n",
    "\n",
    "questions_res_df.index.rename('Questions', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_res_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_res_df.to_csv(\n",
    "    os.path.join(OUT_PATHS['res_csv_dir'], 'questions_results.csv'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Related to Students' Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we do not need to create a new dataframe because all the data is stored in the score_points_df\n",
    "# therefore, we just store the data\n",
    "score_points_df.index.rename(INDEX_COLUMN, inplace=True)\n",
    "score_points_df.to_csv(\n",
    "    os.path.join(OUT_PATHS['res_csv_dir'], 'students_data.csv'),\n",
    "    columns=[col for col in score_points_df.columns if col not in criteria]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we export the results for the whole test:\n",
    "- Minimum number of score points students get\n",
    "- Maximum number of score points students get\n",
    "- Minimum grade of the students computed based on score points\n",
    "- Maximum grade of the students computed based on score points\n",
    "- Average p value\n",
    "- Average Rit value\n",
    "- Average Rir value\n",
    "- Cronbach's alpha\n",
    "- Standard Error of Measurement (SEM) in score points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styler = final_test_df.style\n",
    "styler = (styler\n",
    "    .format(precision=2)\n",
    ")\n",
    "styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting results for the whole test\n",
    "export_df(styler, 'test_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we export the results for each individual question:\n",
    "- Minimum score per question the students get\n",
    "- Maximum score per question the students get\n",
    "- Minimum amount of score points per question the students get\n",
    "- Maximum amount of score points per question the students get\n",
    "- p value\n",
    "- Rit value\n",
    "- Rir value\n",
    "- Standard deviation of score value per question\n",
    "- Standard deviation of score points value per question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styler = questions_res_df[[\n",
    "    'min_scores', \n",
    "    'max_scores',\n",
    "    'min_student_score_points',\n",
    "    'max_student_score_points',\n",
    "    'avg_student_score_points',\n",
    "    'guess_score_points',\n",
    "    'p', \n",
    "    'Rit', \n",
    "    'Rir', \n",
    "    'stdev',\n",
    "    'stdev_sp'\n",
    "]].style\n",
    "\n",
    "styler = (styler\n",
    "    .highlight_between(subset='p', left=0.0, right=0.25, color='red') # too difficult\n",
    "    .highlight_between(subset='p', left=0.25, right=0.4, color='orange') # difficult\n",
    "    .highlight_between(subset='p', left=0.4, right=0.75, color='green') # normal\n",
    "    .highlight_between(subset='p', left=0.75, right=1, color='red') # too easy\n",
    "    .highlight_between(subset='Rit', left=0.4, right=1, color='green') # very good\n",
    "    .highlight_between(subset='Rit', left=0.3, right=0.4, color='limegreen') # very good\n",
    "    .highlight_between(subset='Rit', left=0.2, right=0.3, color='orange') # mediocre\n",
    "    .highlight_between(subset='Rit', left=0., right=0.2, color='red') # bad\n",
    "    .highlight_between(subset='Rit', left=-1, right=0, color='red') # Bad, good students have answered the question incorrectly and vice versa\n",
    "    .highlight_between(subset='Rir', left=0.4, right=1, color='green') # very good\n",
    "    .highlight_between(subset='Rir', left=0.3, right=0.4, color='limegreen') # very good\n",
    "    .highlight_between(subset='Rir', left=0.2, right=0.3, color='orange') # mediocre\n",
    "    .highlight_between(subset='Rir', left=0., right=0.2, color='red') # bad\n",
    "    .highlight_between(subset='Rir', left=-1, right=0, color='red') # Bad, good students have answered the question incorrectly and vice versa\n",
    "    .format(precision=2)\n",
    ")\n",
    "styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting results for questions\n",
    "export_df(styler, 'questions_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we export the results for each individual student:\n",
    "- Score points of a student per each question\n",
    "- Score points sum of a student (student's score points)\n",
    "- Minimum boundary of the score points confidence interval\n",
    "- Maximum boundary of the score points confidence interval\n",
    "- Minimum grade (if provided)\n",
    "- Maximum grade (if provided)\n",
    "- Minimum grade calculated based on the score points\n",
    "- Maximum grade calculated based on the score points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styler = score_points_df.style\n",
    "\n",
    "styler = (styler\n",
    "    .highlight_between(subset=COMPUTED_GRADE_COLUMN, left=MIN_GRADE, right=CUTOFF_GRADE, color='red')\n",
    "    .highlight_between(subset=COMPUTED_GRADE_COLUMN, left=CUTOFF_GRADE, right=MAX_GRADE, color='green')\n",
    "    .format(precision=2)\n",
    ")\n",
    "\n",
    "if grades is not None:\n",
    "    styler = (styler\n",
    "        .highlight_between(subset=GRADE_COLUMN, left=MIN_GRADE, right=CUTOFF_GRADE, color='red')\n",
    "        .highlight_between(subset=GRADE_COLUMN, left=CUTOFF_GRADE, right=MAX_GRADE, color='green')\n",
    "    )\n",
    "    \n",
    "styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exproting the results using figure\n",
    "export_df(styler, 'students_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this table, you can find the correlation between the criteria. If two criteria have a high, positive correlation (colored red in the table), they may measure the same thing. This indicates that you could combine them (if it makes sense). If they should not measure the same thing, you could make it more explicit in e.g. the criterion name or level descriptors what the difference is. On the other hand, if the correlation is quite negative (blue), the concepts are measuring the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = normalized_weighted_scores_df.corr()\n",
    "corr_df.columns.rename(None, inplace=True)\n",
    "corr_df.index.rename(None, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styler = (corr_df.style\n",
    "    .background_gradient(cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    .format(precision=2)\n",
    ")\n",
    "styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exproting questions correlation\n",
    "export_df(styler, 'questions_correlation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table also shows the correlation with the grade. If the correlation with the grade is negative (blue), it says that students who do good in this course, don't do good on this criterion (or the other way around). Is there a specific group of students that could explain this? How could you help them? An example is that students who do good in the math-part of a project, might not do well on report-writing. If the correlation with the grade is around 0 (whitish), it says that the score on this criterion does not say anything about whether students did good in the course or not. Assuming that students who did well in the course do so because they participated in all learning activities, It is an indication that students were not trained on this criterion.  Check whether this criterion is constructively aligned (i.e. do student get training and feedback on this, during the course?). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comp_grade_corr = score_points_df.corrwith(score_points_df[COMPUTED_GRADE_COLUMN])\n",
    "grade_corr_data = {\n",
    "    f'with_{COMPUTED_GRADE_COLUMN}' : score_points_df.corrwith(score_points_df[COMPUTED_GRADE_COLUMN]),\n",
    "}\n",
    "if grades is not None:\n",
    "    grade_corr_data[f'with_{GRADE_COLUMN}'] = score_points_df.corrwith(score_points_df[GRADE_COLUMN])\n",
    "\n",
    "\n",
    "grades_corr_df = pd.DataFrame.from_records(\n",
    "    grade_corr_data,\n",
    "    index=criteria,\n",
    "    columns=grade_corr_data.keys()\n",
    ")\n",
    "\n",
    "grades_corr_df.index.rename('Questions', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styler = (grades_corr_df.style\n",
    "    .background_gradient(cmap='coolwarm', vmin=-1, vmax=1)\n",
    "    .format(precision=2)\n",
    ")\n",
    "styler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exproting questions correlation\n",
    "export_df(styler, 'questions_correlation_with_grade')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_normalized_scores_df = pd.DataFrame(100*normalized_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "perc_normalized_scores_df.boxplot(ax=ax)\n",
    "ax.tick_params(axis='x', labelrotation = -90)\n",
    "ax.set(ylabel='Correct, %')\n",
    "# fig.show()\n",
    "savefig(fig, 'questions_boxplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Score Points Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "score_points_df[STUDENT_SCORE_POINTS_COLUMN].plot.hist(\n",
    "    bins=range(0, 100, 10),\n",
    "    ax=ax,\n",
    "    xticks=range(0, 101, 10),\n",
    "    xlim=(-5,105)\n",
    ")\n",
    "ax.set_xlabel('Score Points')\n",
    "ax.set_ylabel('# Students')\n",
    "ax.set_title(\"Cronbach's alpha: {:.2f}, SEM: {:.2f}\".format(alpha, SEM_SP))\n",
    "# fig.show()\n",
    "savefig(fig, 'score_points')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "if grades is not None:\n",
    "    score_points_df[[GRADE_COLUMN, COMPUTED_GRADE_COLUMN]].plot.hist(\n",
    "        ax=ax,\n",
    "        bins=range(MIN_GRADE, MAX_GRADE+1, 1),\n",
    "        xticks=range(MIN_GRADE, MAX_GRADE+1, 1),\n",
    "        xlim=(MIN_GRADE-1, MAX_GRADE+1),\n",
    "        alpha=0.7,\n",
    "    )\n",
    "    ax.legend(loc='upper left', labels=['PROVIDED GRADE', 'COMPUTED GRADE'])\n",
    "else:\n",
    "    score_points_df[COMPUTED_GRADE_COLUMN].plot.hist(\n",
    "        ax=ax,\n",
    "        bins=range(MIN_GRADE, MAX_GRADE+1, 1),\n",
    "        xticks=range(MIN_GRADE, MAX_GRADE+1, 1),\n",
    "        xlim=(MIN_GRADE-1, MAX_GRADE+1),\n",
    "    )\n",
    "    ax.legend(loc='upper left', labels=['COMPUTED GRADE'])\n",
    "ax.set_xlabel('Grade')\n",
    "ax.set_ylabel('# Students')\n",
    "\n",
    "savefig(fig, 'grades_distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "if grades is not None:\n",
    "    ax.plot(\n",
    "        score_points_df.index,\n",
    "        score_points_df[GRADE_COLUMN],\n",
    "        'b-',\n",
    "        label='PROVIDED GRADE',\n",
    "    )\n",
    "\n",
    "ax.plot(\n",
    "    score_points_df.index,\n",
    "    score_points_df[COMPUTED_GRADE_COLUMN],\n",
    "    'g-',\n",
    "    label='COMPUTED GRADE',\n",
    ")\n",
    "ax.legend()\n",
    "ax.set_xlabel(INDEX_COLUMN)\n",
    "ax.set_ylabel('Grade')\n",
    "savefig(fig, 'grades_for_students')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "\n",
    "ax.fill_between(questions_res_df.index,\n",
    "    questions_res_df['avg_student_score_points'] - questions_res_df['stdev_sp'], \n",
    "    questions_res_df['avg_student_score_points'] + questions_res_df['stdev_sp'], \n",
    "    alpha=0.5, edgecolor='#00111B', facecolor='#229848',\n",
    "    label='avg+-stdev'\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    questions_res_df.index,\n",
    "    questions_res_df['avg_student_score_points'],\n",
    "    'r--',\n",
    "    label = 'avg score',\n",
    ")\n",
    "\n",
    "ax.fill_between(questions_res_df.index,\n",
    "    questions_res_df['min_student_score_points'], \n",
    "    questions_res_df['max_student_score_points'],\n",
    "    alpha=0.5, edgecolor='#CC4F1B', facecolor='#FF9848',\n",
    "    label = 'min-max score',\n",
    ")\n",
    "\n",
    "ax.legend()\n",
    "ax.tick_params(axis='x', labelrotation = -90)\n",
    "ax.set_ylabel('Score Points per Question')\n",
    "# fig.show()\n",
    "savefig(fig, 'questions_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=FIGSIZE)\n",
    "\n",
    "ax.fill_between(score_points_df.index,\n",
    "    score_points_df['MIN_CI_68'],\n",
    "    score_points_df['MAX_CI_68'], \n",
    "    alpha=0.5, facecolor='#229848',\n",
    "    label='CI_68'\n",
    ")\n",
    "\n",
    "ax.fill_between(score_points_df.index,\n",
    "    score_points_df['MIN_CI_95'],\n",
    "    score_points_df['MAX_CI_95'], \n",
    "    alpha=0.5, facecolor='#FF9848',\n",
    "    label='CI_95'\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    score_points_df.index,\n",
    "    score_points_df[STUDENT_SCORE_POINTS_COLUMN],\n",
    "    'r--',\n",
    "    label='score points',\n",
    ")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel(INDEX_COLUMN)\n",
    "ax.set_ylabel('Total Score Points')\n",
    "# fig.show()\n",
    "savefig(fig, 'students_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "201b0e796b5d0b09df9f860fc4d0d8a29c9e47ee16cac1f024d22c5f530e2507"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
